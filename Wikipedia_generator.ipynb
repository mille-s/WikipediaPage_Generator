{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille-s/WikipediaPage_Generator/blob/main/Wikipedia_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdV8-G7AX9Qu",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title Step 1: Prepare repo\n",
        "# Run this cell to download and unzip the working folder and install Java 8\n",
        "\n",
        "from IPython.display import clear_output, HTML, display\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "root_folder = '/content'\n",
        "\n",
        "# clone main repo\n",
        "! git clone https://github.com/mille-s/DCU_TCD_FORGe_WebNLG23.git\n",
        "# Delete locally to avoid confusion\n",
        "! rm 'DCU_TCD_FORGe_WebNLG23/DCU_TCD_FORGe_WebNLG23.ipynb'\n",
        "\n",
        "# clone M-FleNS repo (generation pipeline)\n",
        "! git clone https://github.com/mille-s/M-FleNS_NLG-Pipeline.git\n",
        "# Delete locally to avoid confusion\n",
        "! rm 'M-FleNS_NLG-Pipeline/M_FleNS_pipe_v2.ipynb'\n",
        "\n",
        "# clone wikipedia page generator repo\n",
        "! git clone https://github.com/mille-s/WikipediaPage_Generator.git\n",
        "# Delete locally to avoid confusion\n",
        "! rm 'WikipediaPage_Generator/Wikipedia_generator.ipynb'\n",
        "\n",
        "# Unzip FORGe\n",
        "zipForge = os.path.join(root_folder, 'M-FleNS_NLG-Pipeline', 'code', 'FORGe_colab_v4.zip')\n",
        "! unzip {zipForge} -d {root_folder}\n",
        "\n",
        "# Unzip triple to predArg conversion\n",
        "triple2predArg = os.path.join(root_folder, 'triples2predArg')\n",
        "os.makedirs(triple2predArg)\n",
        "zipPredArg =  os.path.join(root_folder, 'WikipediaPage_Generator', 'code', 'triples2predArg.zip')\n",
        "! unzip {zipPredArg} -d {triple2predArg}\n",
        "triple2Conll_jar = os.path.join(triple2predArg, 'webNLG_triples2conll.jar')\n",
        "\n",
        "# Unzip Morphology generator\n",
        "morph_folder_name = 'test_irish_morph_gen_v5.0'\n",
        "zipMorph = os.path.join(root_folder, 'DCU_TCD_FORGe_WebNLG23', 'code', morph_folder_name+'.zip')\n",
        "! unzip {zipMorph} -d {root_folder}\n",
        "morph_input_folder = os.path.join(root_folder, morph_folder_name, 'Inputs')\n",
        "morph_output_folder = os.path.join(root_folder, morph_folder_name, 'Outputs')\n",
        "os.makedirs(morph_input_folder)\n",
        "os.makedirs(morph_output_folder)\n",
        "# Make morphology flookup executable\n",
        "! 7z a -sfx {morph_folder_name}'/flookup.exe' {morph_folder_name}'/flookup'\n",
        "! chmod 755 {morph_folder_name}'/flookup'\n",
        "\n",
        "# Unzip mock Wikipedia headers\n",
        "zipWikiImg = os.path.join(root_folder, 'WikipediaPage_Generator', 'code', 'wikipedia-images.zip')\n",
        "! unzip {zipWikiImg} -d {triple2predArg}\n",
        "\n",
        "# Install SPARQLWrapper and download list of properties\n",
        "! pip install SPARQLWrapper\n",
        "props_list_path = os.path.join(root_folder, 'DCU_TCD_FORGe_WebNLG23', 'code', 'sorted_properties.txt')\n",
        "\n",
        "clear_output()\n",
        "print('Working folder ready!\\n--------------\\nInstalling Java 8...\\n')\n",
        "\n",
        "# Switch to Java 1.8 (needed for FORGe to run correctly)\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "  !java -version       #check java version\n",
        "install_java()\n",
        "\n",
        "# To wrap texts in cells\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgraqZRd3RWB"
      },
      "source": [
        "# Step 2: Get DBpedia properties associated with an entity name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AiNEj7cLylvu"
      },
      "outputs": [],
      "source": [
        "# @title Set parameters\n",
        "\n",
        "############# Type entity #############\n",
        "name = 'Marie Curie'#@param {type:\"string\"}\n",
        "entity_name = ('_').join(name.split(' '))\n",
        "\n",
        "############# Select class #############\n",
        "category = 'Scientist'#@param['Unknown', 'Airport', 'Artist', 'Astronaut', 'Athlete', 'Building', 'CelestialBody', 'City', 'ComicsCharacter', 'Company', 'Film', 'Food', 'MeanOfTransportation', 'Monument', 'MusicalWork', 'Politician', 'Scientist', 'SportsTeam', 'University', 'WrittenWork']\n",
        "input_category = category\n",
        "\n",
        "############# Select language #############\n",
        "language = 'EN' #@param['EN', 'ES', 'GA']\n",
        "\n",
        "############# Triple source #############\n",
        "# To select where to get the triples from. Ontology is supposed to be cleaner but have less coverage.\n",
        "triple_source = 'Ontology' #@param['Ontology', 'Infobox']\n",
        "\n",
        "############# Set properties to discard #############\n",
        "ignore_properties = 'width, title'#@param {type:\"string\"}\n",
        "# print(ignore_properties_list)\n",
        "\n",
        "############# Select module grouping #############\n",
        "# Group consecutive modules for the same system or call each module separately.\n",
        "# Select 'no' to get all intermediate representations, 'yes' if you're only interested in the output.\n",
        "generate_intermediate_representations = 'no' #@param['yes', 'no']\n",
        "group_modules_prm = ''\n",
        "if generate_intermediate_representations == 'yes':\n",
        "  group_modules_prm = 'no'\n",
        "else:\n",
        "  group_modules_prm = 'yes'\n",
        "\n",
        "############# Select dataset split #############\n",
        "split = \"test\" #@param['dev', 'test','train','ukn']\n",
        "\n",
        "# print('Parameters set!')\n",
        "# print(entity_name)\n",
        "# print(input_category)\n",
        "# print(ignore_properties_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSw0hkloXnV4",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Get DBpedia properties online\n",
        "import os\n",
        "import codecs\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Layout\n",
        "from WikipediaPage_Generator.code.queryDBpediaProps import get_dbpedia_properties\n",
        "\n",
        "# Format properties for passing as argument to python module\n",
        "list_triple_objects, list_propObj, list_obj = get_dbpedia_properties(props_list_path, entity_name, triple_source, ignore_properties)\n",
        "\n",
        "# Create property selector\n",
        "selected_properties = widgets.SelectMultiple(\n",
        "    options=list_propObj,\n",
        "    value=[],\n",
        "    rows=len(list_propObj),\n",
        "    description='Properties',\n",
        "    layout=Layout(width='642px'),\n",
        "    disabled=False\n",
        ")\n",
        "display(selected_properties)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMI7l59Z84B3"
      },
      "source": [
        "# Step 3: Generate text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn-kiZwI9h1X"
      },
      "source": [
        "## Generation parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_properties)"
      ],
      "metadata": {
        "id": "Lm3kzZpE9omM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIntos-p9Y-H"
      },
      "outputs": [],
      "source": [
        "#######################################################################\n",
        "\n",
        "# Modules to run, with type of processing (FORGe, Model1, SimpleNLG, etc.).\n",
        "# Only FORGe is supported for this prototype version.\n",
        "PredArg_Normalisation = 'FORGe'\n",
        "# To have an external module assigning triples to aggregate\n",
        "PredArg_AggregationMark = 'None'\n",
        "PredArg_Aggregation = 'FORGe'\n",
        "PredArg_PoSTagging = 'FORGe'\n",
        "PredArg_CommStructuring = 'FORGe'\n",
        "DSynt_Structuring = 'FORGe'\n",
        "SSynt_Structuring = 'FORGe'\n",
        "SSynt_Aggregation = 'FORGe'\n",
        "RE_Generation = 'FORGe'\n",
        "DMorph_AgreementsLinearisation = 'FORGe'\n",
        "SMorph_Processing = 'FORGe'\n",
        "\n",
        "#######################################################################\n",
        "# Paths to python files\n",
        "path_MFleNS = os.path.join(root_folder, 'M-FleNS_NLG-Pipeline', 'code', 'M-FleNS.py')\n",
        "path_checkOutputs = os.path.join(root_folder, 'M-FleNS_NLG-Pipeline', 'code', 'M-FleNS-checkOutputs.py')\n",
        "path_postProc = os.path.join(root_folder, 'M-FleNS_NLG-Pipeline', 'code', 'postProcess.py')\n",
        "path_FORGe2Morph = os.path.join(root_folder, 'DCU_TCD_FORGe_WebNLG23', 'code', 'FORGe2Morph.py')\n",
        "path_concatenate = os.path.join(root_folder, 'M-FleNS_NLG-Pipeline', 'code', 'concatenate_files.py')\n",
        "path_getClassGenderDBp = os.path.join(root_folder, 'M-FleNS_NLG-Pipeline', 'code', 'getClassGenderDBpedia.py')\n",
        "# path_MorphGen = '/content/DCU_TCD_FORGe_WebNLG23/code/IrishNLP_MorphGen.py'\n",
        "\n",
        "#######################################################################\n",
        "# Paths to FORGe/MATE folders and property files\n",
        "FORGe_input_folder = os.path.join(root_folder, 'FORGe', 'buddy_project', 'struct')\n",
        "path_MATE = os.path.join(root_folder, 'FORGe', 'buddy-patched.jar')\n",
        "path_props_resources_template = os.path.join(root_folder, 'FORGe', 'mateColabDrive.properties')\n",
        "path_props_levels = os.path.join(root_folder, 'FORGe', 'mateLevels.properties')\n",
        "path_props = os.path.join(root_folder, 'FORGe', '/mate.properties')\n",
        "\n",
        "# Paths to general folders\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "path_strs = os.path.join(root_folder, 'FORGe', 'structures')\n",
        "str_PredArg_folder = os.path.join(path_strs, '00-PredArg')\n",
        "str_PredArgNorm_folder = os.path.join(path_strs, '01-PredArgNorm')\n",
        "str_PredArgAggMark_folder = os.path.join(path_strs, '02-PredArgAggMark')\n",
        "str_PredArgAgg_folder = os.path.join(path_strs, '03-PredArgAgg')\n",
        "str_PredArgPoS_folder = os.path.join(path_strs, '04-PredArgPoS')\n",
        "str_PredArgComm_folder = os.path.join(path_strs, '05-PredArgComm')\n",
        "str_DSynt_folder = os.path.join(path_strs, '06-DSynt')\n",
        "str_SSynt_folder = os.path.join(path_strs, '07-SSynt')\n",
        "str_SSyntAgg_folder = os.path.join(path_strs, '08-SSyntAgg')\n",
        "str_REG_folder = os.path.join(path_strs, '09-REG')\n",
        "str_DMorphLin_folder = os.path.join(path_strs, '10-DMorphLin')\n",
        "str_SMorphText_folder = os.path.join(path_strs, '11-SMorphText')\n",
        "log_folder = os.path.join(root_folder, 'FORGe', 'log')\n",
        "if not os.path.exists(log_folder):\n",
        "  os.makedirs(log_folder)\n",
        "temp_input_folder_morph = os.path.join(root_folder, 'FORGe-out')\n",
        "if not os.path.exists(temp_input_folder_morph):\n",
        "  os.makedirs(temp_input_folder_morph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB1FkV2V5alI"
      },
      "source": [
        "## Step 3.1: Convert DBpedia triples to linguistic structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGeXtgqxoSPb"
      },
      "outputs": [],
      "source": [
        "#@title Convert chosen triples to XML and create LLM prompt\n",
        "from WikipediaPage_Generator.code.utils import get_prop_index_from_table, removeReservedCharsFileName, create_xml, create_GPT_Prompt\n",
        "\n",
        "# Generate list of indices of properties selected by user (index in the list of Triple objects that contains all retrieved triples)\n",
        "properties_selected_by_user = get_prop_index_from_table(selected_properties, list_triple_objects)\n",
        "\n",
        "# create xml file and retrieve the list of triples in a text format to build a ChatGPT query, saved in GPT_prompt_{entity}.txt on the left\n",
        "list_triples_text = create_xml(list_triple_objects, properties_selected_by_user, input_category, triple2predArg)\n",
        "\n",
        "# Create a text file that contains a prompt that can be used to produce another version of the current text with GPT.\n",
        "create_GPT_Prompt(entity_name, language, list_triples_text, '/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHLg4mNsRUfj"
      },
      "outputs": [],
      "source": [
        "#@title Get and write class and gender information from DBpedia\n",
        "from WikipediaPage_Generator.code.utils import create_jsons_SubjAndObj\n",
        "\n",
        "# Create json files for entities we need to query DBpedia about\n",
        "filepath_subj, filepath_obj = create_jsons_SubjAndObj(entity_name, list_obj, triple2predArg)\n",
        "# Get class and gender via DBpedia query\n",
        "! python {path_getClassGenderDBp} {filepath_subj} {filepath_obj} {root_folder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGu3-Vj75gQc"
      },
      "outputs": [],
      "source": [
        "#@title  Create FORGe input file (conll format)\n",
        "import shutil\n",
        "from WikipediaPage_Generator.code.utils import prepare_variables_xml2CoNLL_conversion\n",
        "\n",
        "# Get all variables\n",
        "new_triple2predArg, name_conll_templates, path_t2p_out, language_t2p, newEntityName = prepare_variables_xml2CoNLL_conversion(str_PredArg_folder, language, entity_name, triple2predArg)\n",
        "# Convert xml into predArg\n",
        "!java -jar {triple2Conll_jar} {new_triple2predArg} {name_conll_templates} '230528-WebNLG23_EN-GA_properties.txt' {path_t2p_out} {language_t2p} {newEntityName}  # -> \"log.txt\"\n",
        "\n",
        "# Copy conll file to FORGe input folder\n",
        "shutil.copy(os.path.join(path_t2p_out, newEntityName+'_'+language_t2p+'.conll'), str_PredArg_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hs0EEb-5ppQ"
      },
      "source": [
        "## Step 3.2: Convert linguistic structures into non-inflected Irish text (FORGe generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSje-IhV5pH4"
      },
      "outputs": [],
      "source": [
        "#@title  Launch generation process\n",
        "! python {path_MFleNS} {language} {split} {group_modules_prm} {PredArg_Normalisation} {PredArg_AggregationMark} {PredArg_Aggregation} {PredArg_PoSTagging} {PredArg_CommStructuring} {DSynt_Structuring} {SSynt_Structuring} {SSynt_Aggregation} {RE_Generation} {DMorph_AgreementsLinearisation} {SMorph_Processing} {FORGe_input_folder} {path_MATE} {path_props_resources_template} {path_props_levels} {path_props} {str_PredArg_folder} {str_PredArgNorm_folder} {str_PredArgAggMark_folder} {str_PredArgAgg_folder} {str_PredArgPoS_folder} {str_PredArgComm_folder} {str_DSynt_folder} {str_SSynt_folder} {str_SSyntAgg_folder} {str_REG_folder} {str_DMorphLin_folder} {str_SMorphText_folder} {log_folder}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_AUx4SF5w4s"
      },
      "outputs": [],
      "source": [
        "#@title Check outputs and copy files to morph folder\n",
        "from WikipediaPage_Generator.code.utils import clear_folder\n",
        "\n",
        "! python {path_checkOutputs} {str_PredArg_folder} {str_SMorphText_folder} {log_folder} {temp_input_folder_morph} {language}\n",
        "\n",
        "if not language == 'GA':\n",
        "  clear_folder(os.path.join(temp_input_folder_morph, split))\n",
        "  # For GA, files are copied from the python code called above\n",
        "  ! python {path_concatenate} {str_SMorphText_folder} {temp_input_folder_morph} {split}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwt_QCsb5yvk"
      },
      "source": [
        "## Step 3.3: Inflect Irish text (Irish NLP tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQkLf0cJ582k"
      },
      "outputs": [],
      "source": [
        "#@title Process raw FORGe output and format it for Morphology\n",
        "from WikipediaPage_Generator.code.utils import clear_files, count_expected_texts\n",
        "\n",
        "count_strs_all_FORGe = count_expected_texts(root_folder)\n",
        "print('Expected texts: '+str(count_strs_all_FORGe)+'.\\n')\n",
        "\n",
        "if language == 'GA':\n",
        "  ! python {path_FORGe2Morph} {language} {temp_input_folder_morph} {morph_input_folder}\n",
        "  clear_files(temp_input_folder_morph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BROPwE05-iF"
      },
      "outputs": [],
      "source": [
        "#@title Run the morphology generation\n",
        "from DCU_TCD_FORGe_WebNLG23.code.GA_inflect import run_GA_morphGen\n",
        "\n",
        "show_input = False #@param {type:\"boolean\"}\n",
        "\n",
        "if language == 'GA':\n",
        "  run_GA_morphGen(root_folder, morph_folder_name, morph_input_folder, morph_output_folder, count_strs_all_FORGe, show_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A-5vnL46Dy0"
      },
      "source": [
        "## Step 3.4: Post-process output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmpUvibw6H2z"
      },
      "outputs": [],
      "source": [
        "#@title Process texts\n",
        "from WikipediaPage_Generator.code.utils import check_postProcessed_outputs\n",
        "\n",
        "prefinal_output_folder = ''\n",
        "if language == 'GA':\n",
        "  prefinal_output_folder = morph_output_folder\n",
        "else:\n",
        "  prefinal_output_folder = os.path.join(temp_input_folder_morph, split)\n",
        "\n",
        "# Post-process texts\n",
        "! python {path_postProc} {language} {prefinal_output_folder}\n",
        "\n",
        "# Check post-processed texts\n",
        "check_postProcessed_outputs(root_folder, prefinal_output_folder, count_strs_all_FORGe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_fZLFg06Jnz"
      },
      "outputs": [],
      "source": [
        "#@title Concatenate files\n",
        "# import glob\n",
        "from WikipediaPage_Generator.code.utils import concatenate_files_UI\n",
        "\n",
        "filename = concatenate_files_UI(root_folder, morph_output_folder, temp_input_folder_morph, split, language, count_strs_all_FORGe, entity_name, '/content')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ayh52376LLE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Zip and download FORGE output folder and intermediate representations\n",
        "# from google.colab import files\n",
        "# zip_name_inter = '/content/WebNLG_['+language+']_['+split+']_allLevels.zip'\n",
        "# !zip -r {zip_name_inter} /content/FORGe/structures\n",
        "\n",
        "# clear_output()\n",
        "\n",
        "# files.download(zip_name_inter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FewbcFh96MOT",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Zip and download FORGe log files folder\n",
        "# from google.colab import files\n",
        "# zip_name_log = '/content/WebNLG_['+language+']_['+split+']_logs.zip'\n",
        "# !zip -r {zip_name_log} /content/FORGe/log\n",
        "\n",
        "# clear_output()\n",
        "\n",
        "# files.download(zip_name_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Show text - You can download the *_EN.txt or *_GA.txt file at the bottom on the leftside"
      ],
      "metadata": {
        "id": "YKdQerUWtepC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y2WAncs3NjO"
      },
      "outputs": [],
      "source": [
        "#@title Show text\n",
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "display(Image('/content/triples2predArg/wikipedia-header.png', width=1400, height=82))\n",
        "title = '#'+name+''\n",
        "display(Markdown(title))\n",
        "display(Image('/content/triples2predArg/wikipedia-subheader.png', width=1110, height=82))\n",
        "\n",
        "with codecs.open(filename, 'r', 'utf-8') as text:\n",
        "  for line in text:\n",
        "    print(line)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Jn-kiZwI9h1X"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyM+/+79QEoVTznKXRtFuHm5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}